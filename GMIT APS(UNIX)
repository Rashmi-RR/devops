#!/bin/bash

# =============================
# Variables
# =============================
SBASE="/RASE/apps/sharos/fiin_transfer"
SCOMMON_PATH="/data/ape_scripts/archival_scripts/apps_shares_files_transfer_archive"
SDEST="/apps/posttrade/archives/appe_shares_files_transfer"
SINTER_PATH="/data/aps_scripts/archival_scripts/apps_shares_files_transfer_archive/intermediate_data"
SSCRIPT="/data/ape_scripts/archival_scripts/appe_shares_files_transfer_archive/script"
SLOG="$SSCRIPT/logs"

curr_date=$(date '+%Y-%m-%d_%H%M%S')

# =============================
# Check if the base directory exists
# =============================
if [ ! -d "$SBASE" ]; then
  echo "Directory does not exist: $SBASE" >> "$SLOG/FilesharesArchival_$curr_date.log"
  exit 1
fi

# =============================
# Create intermediate directories if missing
# =============================
[ ! -d "$SINTER_PATH" ] && mkdir -p "$SINTER_PATH"
[ ! -d "$SLOG" ] && mkdir -p "$SLOG"

# =============================
# Change to the intermediate path
# =============================
cd "$SINTER_PATH" || exit 1

# =============================
# Find files to archive (older than 10 days)
# =============================
find "$SBASE" -type f -mtime +10 > "$SBASE/ArchiveFilesList_$curr_date.txt"

echo "Start of archiving process" > "$SLOG/FilesharesArchival_$curr_date.log"

archive_file_count=$(wc -l < "$SBASE/ArchiveFilesList_$curr_date.txt")

# =============================
# Process files and remove duplicates
# =============================
while read -r file; do
  filename=$(basename "$file")
  filemonth=$(echo "$filename" | grep -Eo '[0-9]{6}')
  echo "$file" >> "$SINTER_PATH/${filemonth}_files.txt"
done < "$SBASE/ArchiveFilesList_$curr_date.txt"

# =============================
# Deduplicate intermediate files
# =============================
for f in "$SINTER_PATH"/*_files.txt; do
  # ✅ Keep only unique entries (remove duplicates, preserve order)
  awk '!seen[$0]++' "$f" > "${f}.dedup"
  mv "${f}.dedup" "$f"
done

# =============================
# Archive by month
# =============================
for f in "$SINTER_PATH"/*_files.txt; do
  filemonth=$(basename "$f" | grep -Eo '[0-9]{6}')
  tarfile="$SDEST/Archive_${filemonth}.tar.gz"

  if [ -f "$tarfile" ]; then
    echo "$(date '+%Y-%m-%d %H:%M:%S') Checking for duplicates in $tarfile" >> "$SLOG/FilesharesArchival_$curr_date.log"

    gunzip "$tarfile"
    tarfile_unzipped="${tarfile%.gz}"
    tar tf "$tarfile_unzipped" | sort | uniq > existing_files.txt
    gzip "$tarfile_unzipped"

    # Find duplicates
    while read -r line; do
      if grep -q "$line" existing_files.txt; then
        echo "$line" >> duplicate_files.txt
      fi
    done < "$f"

    # ✅ Remove duplicates from $f
    grep -vxF -f duplicate_files.txt "$f" > temp && mv temp "$f"
  fi

  # =============================
  # Final file list (unique only)
  # =============================
  cat "$f" | sort | uniq > final_files.txt

  # =============================
  # Archive unique files
  # =============================
  if [ -s final_files.txt ]; then
    tar -rvf "${tarfile%.gz}" -T final_files.txt
    gzip -f "${tarfile%.gz}"
  fi

  rm -f existing_files.txt duplicate_files.txt final_files.txt
done

# =============================
# Count validation
# =============================
total_count=0
for tarfile in "$SDEST"/*.tar.gz; do
  count=$(tar -tzf "$tarfile" | wc -l)
  total_count=$((total_count + count))
done

echo "Total files in all archives: $total_count" >> "$SLOG/FilesharesArchival_$curr_date.log"
echo "Total files in ArchiveFilesList: $archive_file_count" >> "$SLOG/FilesharesArchival_$curr_date.log"

if [ "$total_count" -eq "$archive_file_count" ]; then
  echo "File counts match: Archival process successful" >> "$SLOG/FilesharesArchival_$curr_date.log"
else
  echo "File count mismatch: Archival process may have issues" >> "$SLOG/FilesharesArchival_$curr_date.log"
fi